from fastapi import APIRouter, HTTPException
from openai import AsyncOpenAI
from config import OPENAI_API_KEY
from models.request import GPTRequest, MindMapRequest, NodeSummaryRequest
import json

router = APIRouter()
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ë…¸ë“œ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì¡´ì¬ ì—¬ë¶€ í™•ì¸)
def get_node_text(node, field, default="ì—†ìŒ"):
    return getattr(node, field, default) if node else default

# ì¼ì • ë§ˆì¸ë“œë§µ ë…¸ë“œ ìƒì„± (GPT ì¶”ì²œ ì§ˆë¬¸)
@router.post("/generate_schedule")
async def generate_schedule_node(request: GPTRequest):
    try:
        # mainNode.summary í•„ìˆ˜ê°’ ê²€ì¦
        if not request.mainNode or not request.mainNode.summary or not request.mainNode.summary.strip():
            raise HTTPException(status_code=400, detail="mainNode.summary ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë§ˆì¸ë“œë§µ íë¦„ ì •ë¦¬
        path_text_parts = [f"ğŸŸ¢ ì „ì²´ ì£¼ì œ: **{request.mainNode.summary}**"]

        if request.parentNode:
            path_text_parts.append(f"ğŸ”¹ **ì´ì „ íë¦„ (ë¶€ëª¨ ë…¸ë“œ)**\n- {get_node_text(request.parentNode, 'summary')}")

        if request.selectedNode:
            path_text_parts.append(f"ğŸ”¹ **í˜„ì¬ ì„ íƒëœ ë…¸ë“œ**\n- {get_node_text(request.selectedNode, 'summary')}")

        path_text = "\n".join(path_text_parts)

        # GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ '{request.mainNode.summary}'ì— ëŒ€í•œ ì¼ì • ë§ˆì¸ë“œë§µì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.

        í˜„ì¬ê¹Œì§€ì˜ ë§ˆì¸ë“œë§µ íë¦„:
        {path_text}

        ì´ ë§ˆì¸ë“œë§µì€ ì‚¬ìš©ìê°€ ì¼ì • ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” ìš©ë„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **'{request.mainNode.summary}'ì™€ ê´€ë ¨ëœ ì¼ì • ê³„íšì„ ì„¸ìš°ëŠ” ë° ìœ ìš©í•œ ì¶”ê°€ ì§ˆë¬¸ 6ê°œ**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

        ì§ˆë¬¸ì€ **ë¦¬ìŠ¤íŠ¸ í˜•íƒœ**ë¡œ ì œê³µí•˜ê³ , **ìˆ«ì, ê¸°í˜¸, ë”°ì˜´í‘œ ì—†ì´** ìˆœìˆ˜í•œ ì§ˆë¬¸ ë‚´ìš©ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
        """

        # OpenAI API í˜¸ì¶œ (ë¹„ë™ê¸° ì²˜ë¦¬)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¼ì • ë§ˆì¸ë“œë§µ ì§ˆë¬¸ ìƒì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì¼ì •ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë•ê³ , ì¼ì • ê³„íšì— ì´ˆì ì„ ë§ì¶˜ ì§ˆë¬¸ì„ ì œê³µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ]
        )

        # ì‘ë‹µ ì²˜ë¦¬ (ë¶ˆí•„ìš”í•œ ìˆ«ì ë° ê¸°í˜¸ ì œê±°)
        generated_text = response.choices[0].message.content
        clean_questions = [q.lstrip("0123456789.- ").strip().strip("'\"") for q in generated_text.split("\n") if q.strip()]

        return {"generated_questions": clean_questions}

    except HTTPException as e:
        raise e  # ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•œ 400 ì—ëŸ¬ ë°˜í™˜
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µ ë…¸ë“œ ìƒì„± (GPT ì¶”ì²œ ì§ˆë¬¸)
@router.post("/generate_thought")
async def generate_thought_node(request: GPTRequest):
    try:
        # mainNode.summary í•„ìˆ˜ê°’ ê²€ì¦
        if not request.mainNode or not request.mainNode.summary or not request.mainNode.summary.strip():
            raise HTTPException(status_code=400, detail="mainNode.summary ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë§ˆì¸ë“œë§µ íë¦„ ì •ë¦¬
        path_text_parts = [f"ğŸŸ¢ ì „ì²´ ì£¼ì œ: **{request.mainNode.summary}**"]

        if request.parentNode:
            path_text_parts.append(f"ğŸ”¹ **ì´ì „ íë¦„ (ë¶€ëª¨ ë…¸ë“œ)**\n- {get_node_text(request.parentNode, 'summary')}")

        if request.selectedNode:
            path_text_parts.append(f"ğŸ”¹ **í˜„ì¬ ì„ íƒëœ ë…¸ë“œ**\n- {get_node_text(request.selectedNode, 'summary')}")

        path_text = "\n".join(path_text_parts)

        # GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ '{request.mainNode.summary}'ì— ëŒ€í•œ ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.

        í˜„ì¬ê¹Œì§€ì˜ ë§ˆì¸ë“œë§µ íë¦„:
        {path_text}

        ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸ 6ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì§ˆë¬¸ì€ **ë¦¬ìŠ¤íŠ¸ í˜•íƒœ**ë¡œ ì œê³µí•˜ê³ , **ìˆ«ì, ê¸°í˜¸, ë”°ì˜´í‘œ ì—†ì´** ìˆœìˆ˜í•œ ì§ˆë¬¸ ë‚´ìš©ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
        """

        # OpenAI API í˜¸ì¶œ (ë¹„ë™ê¸° ì²˜ë¦¬)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µ ì§ˆë¬¸ ìƒì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê¹Šì´ ìˆëŠ” ìƒê°ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì§ˆë¬¸ì„ ì œê³µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ]
        )

        # ì‘ë‹µ ì²˜ë¦¬ (ë¶ˆí•„ìš”í•œ ìˆ«ì ë° ê¸°í˜¸ ì œê±°)
        generated_text = response.choices[0].message.content
        clean_questions = [q.lstrip("0123456789.- ").strip().strip("'\"") for q in generated_text.split("\n") if q.strip()]

        return {"generated_questions": clean_questions}

    except HTTPException as e:
        raise e  # ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•œ 400 ì—ëŸ¬ ë°˜í™˜
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë§ˆì¸ë“œë§µ ë°ì´í„°ë¥¼ GPT ìš”ì²­ìš© ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜

# ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶€ëª¨-ìì‹ ê´€ê³„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def build_mindmap_tree(nodes):
    """ ë…¸ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë³€í™˜ """
    node_dict = {node.id: {"summary": node.summary, "children": []} for node in nodes}

    root_node = None

    for node in nodes:
        if node.parentId is None:
            root_node = node_dict[node.id]  # ë£¨íŠ¸ ë…¸ë“œ ì°¾ê¸°
        else:
            node_dict[node.parentId]["children"].append(node_dict[node.id])  # ë¶€ëª¨-ìì‹ ì—°ê²°

    return root_node


# íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ GPT ì…ë ¥ìš© ê³„ì¸µí˜• í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
def format_tree_for_gpt(node, depth=0):
    indent = "  " * depth  # ë“¤ì—¬ì“°ê¸° ì„¤ì •
    text = f"{indent}- {node['summary']}\n"

    for child in node["children"]:
        text += format_tree_for_gpt(child, depth + 1)

    return text


# ì¼ì • ë§ˆì¸ë“œë§µì„ TODO ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
@router.post("/convert_schedule_todo")
async def convert_schedule_to_todo(request: MindMapRequest):
    try:
        # ë§ˆì¸ë“œë§µ íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
        mindmap_tree = build_mindmap_tree(request.nodes)

        # GPTì— ì „ë‹¬í•  ê³„ì¸µí˜• í…ìŠ¤íŠ¸ ìƒì„±
        mindmap_text = format_tree_for_gpt(mindmap_tree)

        prompt = f"""
        ì‚¬ìš©ìê°€ ì•„ë˜ ì¼ì • ë§ˆì¸ë“œë§µì„ ê¸°ë°˜ìœ¼ë¡œ ì¼ì • ê³„íšì„ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.
        
        ** ë§ˆì¸ë“œë§µ ê°œìš”**
        {mindmap_text}

        ìœ„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **ì‹¤í–‰ ê°€ëŠ¥í•œ TODO ë¦¬ìŠ¤íŠ¸**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        - ë§ˆì¸ë“œë§µì˜ ë¶€ëª¨-ìì‹ ê´€ê³„ë¥¼ ê³ ë ¤í•˜ì—¬ ë…¼ë¦¬ì ìœ¼ë¡œ êµ¬ì„±.
        - ì‹¤ì²œ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ í˜•íƒœë¡œ ë³€í™˜.
        - ìˆ«ì, ê¸°í˜¸ ì—†ì´ ìˆœìˆ˜í•œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë°˜í™˜.
        - ë§ˆì¸ë“œë§µì˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ë¥¸ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šê³ , ì£¼ì–´ì§„ ì •ë³´ë§Œìœ¼ë¡œ ë³€í™˜.
        - ë°”ë¡œ ë°ì´í„°ë¡œ ì‚¬ìš©í• ê±°ë‹ˆê¹Œ ì œëª©ì€ í•„ìš”ì—†ê³  ë‚´ìš© ë¦¬ìŠ¤íŠ¸ë§Œ ë°˜í™˜.
        - "-"ì™€ ê°™ì€ íŠ¹ìˆ˜ë¬¸ì, ê¸°í˜¸ ì—†ì´ ìˆœìˆ˜í•œ ë‚´ìš©ë§Œ ë°˜í™˜.
        """


        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¼ì • ê³„íšì„ ì •ë¦¬í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        generated_text = response.choices[0].message.content
        todo_list = [item.strip().strip("'\"") for item in generated_text.split("\n") if item.strip()]

        return {"todo_list": todo_list}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µì„ Key-Value ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
@router.post("/convert_thought_list")
async def convert_thought_to_key_value_list(request: MindMapRequest):
    try:
        # ë§ˆì¸ë“œë§µ íŠ¸ë¦¬ êµ¬ì¡° ìƒì„±
        mindmap_tree = build_mindmap_tree(request.nodes)

        # GPTì— ì „ë‹¬í•  ê³„ì¸µí˜• í…ìŠ¤íŠ¸ ìƒì„±
        mindmap_text = format_tree_for_gpt(mindmap_tree)

        prompt = f"""
        ì‚¬ìš©ìê°€ ì•„ë˜ ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µì„ ì‘ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤. 
        
        **ë§ˆì¸ë“œë§µ ê°œìš”**
        {mindmap_text}

        ìœ„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **í•µì‹¬ ë‚´ìš©ì„ Key-Value ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜**í•´ì£¼ì„¸ìš”.
        - KeyëŠ” ì£¼ì œ (summary), ValueëŠ” í•´ë‹¹ ë‚´ìš©ì— ëŒ€í•œ ì§§ì€ ì„¤ëª….
        - Key-Value í˜•íƒœì˜ JSON ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜.
        - JSON ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ë°˜í™˜.
        - ë§ˆì¸ë“œë§µì˜ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ë¥¸ ì •ë³´ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šê³ , ì£¼ì–´ì§„ ì •ë³´ë§Œìœ¼ë¡œ ë³€í™˜.
        - ë°”ë¡œ ë°ì´í„°ë¡œ ì‚¬ìš©í• ê±°ë‹ˆê¹Œ ì œëª©ì€ í•„ìš”ì—†ê³  ë‚´ìš©ë§Œ ë°˜í™˜.
        """

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìƒê° ì •ë¦¬ë¥¼ ë•ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        raw_response = response.choices[0].message.content
        clean_json = raw_response.strip("```json").strip("```").strip()  # ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ì œê±°

        key_value_list = json.loads(clean_json)  # JSON ë³€í™˜

        return {"thought_list": key_value_list}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë…¸ë“œ ìš”ì•½ API
@router.post("/summarize_node")
async def summarize_node(request: NodeSummaryRequest):
    try:
        # ë°›ì€ questionê³¼ answerë¥¼ ì‚¬ìš©í•´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.

        **ì§ˆë¬¸:** {request.question}
        **ë‹µë³€:** {request.answer}

        ìœ„ì˜ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        ë¬¸ì¥ì€ **ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©**ë§Œ í¬í•¨í•˜ë©°, ë¶ˆí•„ìš”í•œ ì„¤ëª…ì„ ì œê±°í•´ì£¼ì„¸ìš”.
        
        - ìš”ì•½ ë¬¸ì¥ì€ ì£¼ì–´(ì˜ˆì‹œë¡œ "ì‚¬ìš©ì"ë¼ëŠ” ë‹¨ì–´) ì—†ëŠ” ì™„ì„±ëœ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±.
        """

        # GPT í˜¸ì¶œ (ë¹„ë™ê¸° ì²˜ë¦¬)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì…ë ¥ëœ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        # ì‘ë‹µì—ì„œ ìš”ì•½ ë¬¸ì¥ ì¶”ì¶œ
        summarized_text = response.choices[0].message.content.strip()

        return {"summary": summarized_text}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))