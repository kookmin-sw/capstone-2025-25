from fastapi import APIRouter, HTTPException
from openai import AsyncOpenAI
from config import OPENAI_API_KEY
from models.request import GPTRequest, NodeSummaryRequest, ConvertToTaskRequest

router = APIRouter()
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# ë…¸ë“œ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ì¡´ì¬ ì—¬ë¶€ í™•ì¸)
def get_node_text(node, field, default="ì—†ìŒ"):
    return getattr(node, field, default) if node else default

# ì¼ì • ë§ˆì¸ë“œë§µ ë…¸ë“œ ìƒì„± (GPT ì¶”ì²œ ì§ˆë¬¸)
@router.post("/generate_schedule")
async def generate_schedule_node(request: GPTRequest):
    try:
        # mainNode.summary í•„ìˆ˜ê°’ ê²€ì¦
        if not request.mainNode or not request.mainNode.summary or not request.mainNode.summary.strip():
            raise HTTPException(status_code=400, detail="mainNode.summary ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë§ˆì¸ë“œë§µ íë¦„ ì •ë¦¬
        path_text_parts = [f"ğŸŸ¢ ì „ì²´ ì£¼ì œ: **{request.mainNode.summary}**"]

        if request.parentNode:
            path_text_parts.append(f"ğŸ”¹ **ì´ì „ íë¦„ (ë¶€ëª¨ ë…¸ë“œ)**\n- {get_node_text(request.parentNode, 'summary')}")

        if request.selectedNode:
            path_text_parts.append(f"ğŸ”¹ **í˜„ì¬ ì„ íƒëœ ë…¸ë“œ**\n- {get_node_text(request.selectedNode, 'summary')}")

        path_text = "\n".join(path_text_parts)

        # GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ '{request.mainNode.summary}'ì— ëŒ€í•œ ì¼ì • ë§ˆì¸ë“œë§µì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.

        í˜„ì¬ê¹Œì§€ì˜ ë§ˆì¸ë“œë§µ íë¦„:
        {path_text}

        ì´ ë§ˆì¸ë“œë§µì€ ì‚¬ìš©ìê°€ ì¼ì • ê³„íšì„ ìˆ˜ë¦½í•˜ëŠ” ë° ë„ì›€ì„ ì£¼ëŠ” ìš©ë„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **'{request.mainNode.summary}'ì™€ ê´€ë ¨ëœ ì¼ì • ê³„íšì„ ì„¸ìš°ëŠ” ë° ìœ ìš©í•œ ì¶”ê°€ ì§ˆë¬¸ 6ê°œ**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

        ì§ˆë¬¸ì€ **ë¦¬ìŠ¤íŠ¸ í˜•íƒœ**ë¡œ ì œê³µí•˜ê³ , **ìˆ«ì, ê¸°í˜¸, ë”°ì˜´í‘œ ì—†ì´** ìˆœìˆ˜í•œ ì§ˆë¬¸ ë‚´ìš©ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
        """

        # OpenAI API í˜¸ì¶œ (ë¹„ë™ê¸° ì²˜ë¦¬)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì¼ì • ë§ˆì¸ë“œë§µ ì§ˆë¬¸ ìƒì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì¼ì •ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë•ê³ , ì¼ì • ê³„íšì— ì´ˆì ì„ ë§ì¶˜ ì§ˆë¬¸ì„ ì œê³µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ]
        )

        # ì‘ë‹µ ì²˜ë¦¬ (ë¶ˆí•„ìš”í•œ ìˆ«ì ë° ê¸°í˜¸ ì œê±°)
        generated_text = response.choices[0].message.content
        clean_questions = [q.lstrip("0123456789.- ").strip().strip("'\"") for q in generated_text.split("\n") if q.strip()]

        return {"generated_questions": clean_questions}

    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µ ë…¸ë“œ ìƒì„± (GPT ì¶”ì²œ ì§ˆë¬¸)
@router.post("/generate_thought")
async def generate_thought_node(request: GPTRequest):
    try:
        # mainNode.summary í•„ìˆ˜ê°’ ê²€ì¦
        if not request.mainNode or not request.mainNode.summary or not request.mainNode.summary.strip():
            raise HTTPException(status_code=400, detail="mainNode.summary ê°’ì´ ë¹„ì–´ ìˆê±°ë‚˜ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")

        # ë§ˆì¸ë“œë§µ íë¦„ ì •ë¦¬
        path_text_parts = [f"ğŸŸ¢ ì „ì²´ ì£¼ì œ: **{request.mainNode.summary}**"]

        if request.parentNode:
            path_text_parts.append(f"ğŸ”¹ **ì´ì „ íë¦„ (ë¶€ëª¨ ë…¸ë“œ)**\n- {get_node_text(request.parentNode, 'summary')}")

        if request.selectedNode:
            path_text_parts.append(f"ğŸ”¹ **í˜„ì¬ ì„ íƒëœ ë…¸ë“œ**\n- {get_node_text(request.selectedNode, 'summary')}")

        path_text = "\n".join(path_text_parts)

        # GPTì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ '{request.mainNode.summary}'ì— ëŒ€í•œ ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤.

        í˜„ì¬ê¹Œì§€ì˜ ë§ˆì¸ë“œë§µ íë¦„:
        {path_text}

        ìœ„ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ìƒê°ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê´€ë ¨ëœ ì¶”ê°€ ì§ˆë¬¸ 6ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
        ì§ˆë¬¸ì€ **ë¦¬ìŠ¤íŠ¸ í˜•íƒœ**ë¡œ ì œê³µí•˜ê³ , **ìˆ«ì, ê¸°í˜¸, ë”°ì˜´í‘œ ì—†ì´** ìˆœìˆ˜í•œ ì§ˆë¬¸ ë‚´ìš©ë§Œ í¬í•¨í•´ì£¼ì„¸ìš”.
        """

        # OpenAI API í˜¸ì¶œ (ë¹„ë™ê¸° ì²˜ë¦¬)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìƒê° ì •ë¦¬ ë§ˆì¸ë“œë§µ ì§ˆë¬¸ ìƒì„± ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ê¹Šì´ ìˆëŠ” ìƒê°ì„ ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ” ì§ˆë¬¸ì„ ì œê³µí•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ]
        )

        # ì‘ë‹µ ì²˜ë¦¬ (ë¶ˆí•„ìš”í•œ ìˆ«ì ë° ê¸°í˜¸ ì œê±°)
        generated_text = response.choices[0].message.content
        clean_questions = [q.lstrip("0123456789.- ").strip().strip("'\"") for q in generated_text.split("\n") if q.strip()]

        return {"generated_questions": clean_questions}

    except HTTPException as e:
        raise e  # ëª…ì‹œì ìœ¼ë¡œ ì •ì˜í•œ 400 ì—ëŸ¬ ë°˜í™˜
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/convert_to_task")
async def convert_mindmap_nodes_to_task(request: ConvertToTaskRequest):
    try:
        # Step 1: ë…¸ë“œ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„± (ê°„ë‹¨í•˜ê²Œ ì—°ê²°)
        summaries = [node.summary for node in request.selectedNodes if node.summary.strip()]
        if not summaries:
            raise HTTPException(status_code=400, detail="ìš”ì•½í•  ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")

        node_text = "\n".join(f"- {s}" for s in summaries)

        prompt = f"""
        ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ë§ˆì¸ë“œë§µì—ì„œ ì„ íƒí•œ ë…¸ë“œë“¤ì…ë‹ˆë‹¤:

        {node_text}

        ì´ ë…¸ë“œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ë‚˜ì˜ í•  ì¼(Task)ë¡œ ë§Œë“¤ê³ ì í•©ë‹ˆë‹¤.
        ì´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ í•˜ë‚˜ì˜ ì‘ì—… ì œëª©**ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
        """

        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì—¬ëŸ¬ ë§ˆì¸ë“œë§µ ë…¸ë“œë¥¼ í•˜ë‚˜ì˜ ì‘ì—…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        task_title = response.choices[0].message.content.strip()


        new_task = {
            "title": task_title
        }

        return {"task": new_task}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë…¸ë“œ ìš”ì•½ API
@router.post("/summarize_node")
async def summarize_node(request: NodeSummaryRequest):
    try:
        # ë°›ì€ questionê³¼ answerë¥¼ ì‚¬ìš©í•´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        ì‚¬ìš©ìê°€ ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ì…ë ¥í–ˆìŠµë‹ˆë‹¤.

        **ì§ˆë¬¸:** {request.question}
        **ë‹µë³€:** {request.answer}

        ìœ„ì˜ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
        ë¬¸ì¥ì€ **ê°„ê²°í•˜ê³  í•µì‹¬ì ì¸ ë‚´ìš©**ë§Œ í¬í•¨í•˜ë©°, ë¶ˆí•„ìš”í•œ ì„¤ëª…ì„ ì œê±°í•´ì£¼ì„¸ìš”.
        
        - ìš”ì•½ ë¬¸ì¥ì€ ì£¼ì–´(ì˜ˆì‹œë¡œ "ì‚¬ìš©ì"ë¼ëŠ” ë‹¨ì–´) ì—†ëŠ” ì™„ì„±ëœ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±.
        """

        # GPT í˜¸ì¶œ (ë¹„ë™ê¸° ì²˜ë¦¬)
        response = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì…ë ¥ëœ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ]
        )

        # ì‘ë‹µì—ì„œ ìš”ì•½ ë¬¸ì¥ ì¶”ì¶œ
        summarized_text = response.choices[0].message.content.strip()

        return {"summary": summarized_text}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))